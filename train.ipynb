{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:14:48.293345: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 22:14:49.410557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78911 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:87:00.0, compute capability: 8.0\n",
      "2023-12-06 22:14:49.412308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78911 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 22:14:51.558415: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-12-06 22:14:53.280169: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - 25s 82ms/step - loss: 3.7908 - accuracy: 0.1541\n",
      "Epoch 2/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 3.3248 - accuracy: 0.1899\n",
      "Epoch 3/35\n",
      "264/264 [==============================] - 22s 83ms/step - loss: 3.0241 - accuracy: 0.2494\n",
      "Epoch 4/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 2.7460 - accuracy: 0.3109\n",
      "Epoch 5/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 2.4772 - accuracy: 0.3577\n",
      "Epoch 6/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 2.2139 - accuracy: 0.4169\n",
      "Epoch 7/35\n",
      "264/264 [==============================] - 22s 83ms/step - loss: 1.9966 - accuracy: 0.4781\n",
      "Epoch 8/35\n",
      "264/264 [==============================] - 21s 81ms/step - loss: 1.8130 - accuracy: 0.5307\n",
      "Epoch 9/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.6725 - accuracy: 0.5755\n",
      "Epoch 10/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.5240 - accuracy: 0.6328\n",
      "Epoch 11/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.4213 - accuracy: 0.6784\n",
      "Epoch 12/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.3165 - accuracy: 0.7193\n",
      "Epoch 13/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.2642 - accuracy: 0.7532\n",
      "Epoch 14/35\n",
      "264/264 [==============================] - 22s 81ms/step - loss: 1.2230 - accuracy: 0.7703\n",
      "Epoch 15/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.1504 - accuracy: 0.8004\n",
      "Epoch 16/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.1072 - accuracy: 0.8118\n",
      "Epoch 17/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.0726 - accuracy: 0.8271\n",
      "Epoch 18/35\n",
      "264/264 [==============================] - 21s 81ms/step - loss: 1.0392 - accuracy: 0.8435\n",
      "Epoch 19/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 1.0104 - accuracy: 0.8493\n",
      "Epoch 20/35\n",
      "264/264 [==============================] - 21s 81ms/step - loss: 0.9901 - accuracy: 0.8585\n",
      "Epoch 21/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.9570 - accuracy: 0.8691\n",
      "Epoch 22/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.9258 - accuracy: 0.8748\n",
      "Epoch 23/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.9005 - accuracy: 0.8842\n",
      "Epoch 24/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.8962 - accuracy: 0.8819\n",
      "Epoch 25/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.8713 - accuracy: 0.8922\n",
      "Epoch 26/35\n",
      "264/264 [==============================] - 22s 81ms/step - loss: 0.8577 - accuracy: 0.8941\n",
      "Epoch 27/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.8422 - accuracy: 0.8981\n",
      "Epoch 28/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.8287 - accuracy: 0.8970\n",
      "Epoch 29/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.8066 - accuracy: 0.9010\n",
      "Epoch 30/35\n",
      "264/264 [==============================] - 21s 81ms/step - loss: 0.7808 - accuracy: 0.9075\n",
      "Epoch 31/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.7514 - accuracy: 0.9146\n",
      "Epoch 32/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.7588 - accuracy: 0.9137\n",
      "Epoch 33/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.7389 - accuracy: 0.9163\n",
      "Epoch 34/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.7356 - accuracy: 0.9135\n",
      "Epoch 35/35\n",
      "264/264 [==============================] - 22s 82ms/step - loss: 0.7208 - accuracy: 0.9173\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def load_data():\n",
    "    # Load training data and labels from numpy files\n",
    "    data = np.load('data_train.npy')\n",
    "    labels = np.load('labels_train.npy') \n",
    "    # Reshape and resize data for the model\n",
    "    data_reshaped = data.T.reshape((-1, 300, 300, 3))\n",
    "    resized_data = np.array([resize(img, (100, 100, 3), anti_aliasing=True) for img in data_reshaped])\n",
    "    # Normalize pixel values if necessary\n",
    "    if resized_data.max() > 1.0:\n",
    "        data_normalized = resized_data.astype(np.float32) / 255.0\n",
    "    else:\n",
    "        data_normalized = resized_data\n",
    "    return data_normalized, labels\n",
    "\n",
    "def build_model():\n",
    "    # Define the CNN architecture\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(512, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dense(9, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def random_brightness(image):\n",
    "    # Apply random brightness to an image\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.squeeze(image)\n",
    "    return image\n",
    "\n",
    "def adjust_contrast(img):\n",
    "    # Randomly adjust contrast of an image\n",
    "    contrast_factor = tf.random.uniform([], 0.9, 1.1)\n",
    "    return tf.image.adjust_contrast(img, contrast_factor)\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Preprocess images by applying random brightness and contrast adjustments\n",
    "    img = random_brightness(img)\n",
    "    img = adjust_contrast(img)\n",
    "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "    return img\n",
    "\n",
    "def train():\n",
    "    # Load data and labels\n",
    "    data, labels = load_data()\n",
    "    # Define image data generator for data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=preprocess_image\n",
    "    )\n",
    "    # Build, compile and train the model\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Note: No train-validation split here, using full data for training\n",
    "    train_generator = datagen.flow(data, labels, batch_size=32)\n",
    "    model.fit(train_generator, epochs=35)\n",
    "\n",
    "    # Save final model to a file\n",
    "    model.save('final_model.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
